{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, concatenate, Dropout, Reshape, Conv1D, MaxPooling1D, Flatten, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import sys\n",
    "from ZernikeCNN import ZernikeConv, Normalized_resampleGraph_expand, ZernikeDecomp\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], sio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ZerNet_inputs(path):\n",
    "    ZerNet_preproc = loadmat(path)\n",
    "    Zerbases = ZerNet_preproc['ZerNet_preproc']['scale_1']['ZerPatch']['bases'].astype('float32')\n",
    "    resampleGraph = (ZerNet_preproc['ZerNet_preproc']['scale_1']['ZerPatch']['resamplePids']-1).astype('int32')\n",
    "    return Zerbases,resampleGraph\n",
    "\n",
    "def load_mapping_infor(path):\n",
    "    X2N_mapping_infor = loadmat(path)\n",
    "    mesh_faces = (X2N_mapping_infor['X2N_mapping_infor']['F']-1).astype('int32')\n",
    "    resample_graph_I = (X2N_mapping_infor['X2N_mapping_infor']['scale_1']['I']-1).astype('int32')\n",
    "    resample_graph_B = X2N_mapping_infor['X2N_mapping_infor']['scale_1']['B'].astype('float32')\n",
    "    return mesh_faces, resample_graph_I, resample_graph_B\n",
    "\n",
    "def create_data(patch_path, feature_path, label_path, mapping_infor_path):\n",
    "    Zerbases, resampleGraph = load_ZerNet_inputs(patch_path)  \n",
    "    input_feature = sio.loadmat(feature_path).get('feature_in').astype('float32')\n",
    "    label_out = (sio.loadmat(label_path).get('labels')-1).astype('int32')\n",
    "    \n",
    "    mesh_faces, resample_graph_I, resample_graph_B = load_mapping_infor(mapping_infor_path)\n",
    "    return input_feature,resampleGraph,Zerbases,label_out,mesh_faces,resample_graph_I,resample_graph_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_model_names, patches_folder, features_folder, labels_folder, mapping_infor_path, \n",
    "                 batch_size=1, basis_num = 21, num_input_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.list_model_names = list_model_names\n",
    "        self.patches_folder = patches_folder\n",
    "        self.features_folder = features_folder\n",
    "        self.labels_folder = labels_folder\n",
    "        self.mapping_infor_path = mapping_infor_path\n",
    "        self.basis_num = basis_num\n",
    "        self.batch_size = batch_size\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_model_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        indexes = self.indexes[index:index+1]\n",
    "\n",
    "        # Find list of model_names\n",
    "        list_model_names_temp = [self.list_model_names[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_model_names_temp)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_model_names))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)        \n",
    "\n",
    "    def __data_generation(self, list_model_names_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        model_name = list_model_names_temp[0]\n",
    "\n",
    "        # Generate data\n",
    "        patch_path = os.path.join(self.patches_folder,model_name)\n",
    "        feature_path = os.path.join(self.features_folder,model_name)\n",
    "        label_path = os.path.join(self.labels_folder,model_name)\n",
    "            \n",
    "        input_Feature,resampleGraph,Zerbases,label_out,mesh_faces, resample_graph_I, resample_graph_B = create_data(patch_path, feature_path, label_path, self.mapping_infor_path)\n",
    "        \n",
    "        x_Feature = np.expand_dims(input_Feature,axis=0)\n",
    "        x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "        x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "        \n",
    "        x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "        x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "        x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "        \n",
    "        X = [x_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "        Y = np.expand_dims(label_out, axis=0)\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ZerNet(nrays, n_classes, cut_num, basis_num=21,num_input_channels=3):\n",
    "        \n",
    "    x_Feature = Input(shape=(None,num_input_channels,), dtype = 'float32')\n",
    "    x_rG = Input(shape=(None,None,), dtype = 'int32', name = 'rG')\n",
    "    x_F = Input(shape=(None,3,), dtype = 'int32', name = 'F')\n",
    "    x_I = Input(shape=(None,), dtype = 'int32', name = 'I')\n",
    "    x_B = Input(shape=(None,3,), dtype = 'float32', name = 'B')\n",
    "    Zerbases = Input(shape=(None,None,basis_num,), dtype = 'float32', name = 'Zb')\n",
    "    \n",
    "    Disk_Features = Normalized_resampleGraph_expand(cut_num = cut_num, angular_axis=False)([x_Feature, x_rG, x_F, x_I, x_B])    \n",
    "    Zercoeff = ZernikeDecomp()([Disk_Features,Zerbases])\n",
    "    Features = ZernikeConv(filters = 64, numofrays=nrays, angular_axis = False, angular_expand=True, activation='relu')(Zercoeff)\n",
    "    Features = Dropout(0.25)(Features)\n",
    "\n",
    "    Disk_Features = Normalized_resampleGraph_expand(cut_num = cut_num, angular_axis=True)([Features, x_rG, x_F, x_I, x_B]) \n",
    "    Zercoeff = ZernikeDecomp(angular_axis=True,numofrays=nrays)([Disk_Features,Zerbases])\n",
    "    Features = ZernikeConv(filters = 128, numofrays=nrays, angular_axis = True, angular_pooling=False, activation='relu')(Zercoeff)\n",
    "    Features = Dropout(0.25)(Features)\n",
    "    \n",
    "    Disk_Features = Normalized_resampleGraph_expand(cut_num = cut_num, angular_axis=True)([Features, x_rG, x_F, x_I, x_B])\n",
    "    Zercoeff = ZernikeDecomp(angular_axis=True,numofrays=nrays)([Disk_Features,Zerbases])\n",
    "    Features = ZernikeConv(filters = 256, numofrays=nrays, angular_axis = True, angular_pooling=True, activation='relu')(Zercoeff)\n",
    "    Features = Dropout(0.25)(Features)\n",
    "\n",
    "    Features = Conv1D(filters = 512, kernel_size=1, activation='relu')(Features)\n",
    "    Features = Dropout(0.25)(Features)\n",
    "    Features = Conv1D(filters = n_classes, kernel_size=1, activation='softmax')(Features)\n",
    "\n",
    "    model = Model(inputs = [x_Feature,x_rG, x_F, x_I, x_B, Zerbases], outputs = Features)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "rG (InputLayer)                  (None, None, None)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "F (InputLayer)                   (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "I (InputLayer)                   (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "B (InputLayer)                   (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "normalized_resample_graph_expand (None, None, None, 3) 0           input_1[0][0]                    \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "Zb (InputLayer)                  (None, None, None, 21 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_1 (ZernikeDecomp) (None, None, 21, 3)   0           normalized_resample_graph_expand_\n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_1 (ZernikeConv)     (None, None, 1, 64)   4096        zernike_decomp_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, None, 1, 64)   0           zernike_conv_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "normalized_resample_graph_expand (None, None, 1, None, 0           dropout_1[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_2 (ZernikeDecomp) (None, None, 1, 21, 6 0           normalized_resample_graph_expand_\n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_2 (ZernikeConv)     (None, None, 1, 128)  172160      zernike_decomp_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, None, 1, 128)  0           zernike_conv_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "normalized_resample_graph_expand (None, None, 1, None, 0           dropout_2[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_3 (ZernikeDecomp) (None, None, 1, 21, 1 0           normalized_resample_graph_expand_\n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_3 (ZernikeConv)     (None, None, 256)     688384      zernike_decomp_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, None, 256)     0           zernike_conv_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, None, 512)     131584      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, None, 512)     0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, None, 6890)    3534570     dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4,530,794\n",
      "Trainable params: 4,530,794\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_input_channels = 3\n",
    "cut_num = 50\n",
    "basis_num = 21\n",
    "n_classes = 6890\n",
    "nrays = 1 # nrays = 4\n",
    "\n",
    "model = ZerNet(nrays,n_classes, cut_num, basis_num,num_input_channels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "features_folder = './Data/Faust Corrspondence Dataset/ZerNet Input/Input features'\n",
    "patches_folder = './Data/Faust Corrspondence Dataset/ZerNet Input/Input ZerPatches'\n",
    "labels_folder = './Data/Faust Corrspondence Dataset/ZerNet Output'\n",
    "\n",
    "model_names = os.listdir(features_folder)\n",
    "\n",
    "train_model_names = []\n",
    "for i in range(80):\n",
    "    model_id = 1000+i;\n",
    "    model_id = str(model_id)[1:]\n",
    "    model_name = 'tr_reg_' + model_id + '.mat'\n",
    "    train_model_names.append(model_name)\n",
    "\n",
    "test_model_names = list(set(model_names) - set(train_model_names))\n",
    "\n",
    "# print(train_model_names)\n",
    "# print(test_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "mapping_infor_path = './Data/Faust Corrspondence Dataset/ZerNet Input/X2N_mapping_infor/X2N_mapping_infor.mat'\n",
    "\n",
    "params = {'batch_size': 1,\n",
    "          'basis_num': 21,\n",
    "          'num_input_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_model_names, patches_folder, features_folder, labels_folder, \n",
    "                                   mapping_infor_path, **params)\n",
    "\n",
    "validation_generator = DataGenerator(test_model_names, patches_folder, features_folder, labels_folder, \n",
    "                                   mapping_infor_path, **params)\n",
    "\n",
    "train_steps = len(train_model_names)\n",
    "val_steps = len(test_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss= 'sparse_categorical_crossentropy', optimizer = adam, metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "weights_dir = './Trained Models/faust_train_checkpoints'\n",
    "\n",
    "trained_model_name = 'ZerNet_faust_correspondence'\n",
    "checkpointer = ModelCheckpoint(filepath = os.path.join(weights_dir, trained_model_name),\n",
    "                               monitor = 'val_sparse_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_sparse_categorical_accuracy', min_delta=0.001, patience=35, verbose=0, mode='max')\n",
    "\n",
    "network_history = model.fit_generator(generator=training_generator, steps_per_epoch=train_steps,\n",
    "                                      epochs=200, verbose=1,\n",
    "                                      callbacks=[checkpointer, earlystopping],\n",
    "                                      validation_data=validation_generator,\n",
    "                                      validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(patches_folder, features_folder, labels_folder, mapping_infor_path, model_name):\n",
    "    patch_path = os.path.join(patches_folder,model_name)\n",
    "    feature_path = os.path.join(features_folder,model_name)\n",
    "    label_path = os.path.join(labels_folder,model_name)\n",
    "            \n",
    "    input_Feature,resampleGraph,Zerbases,label_out,mesh_faces, resample_graph_I, resample_graph_B = create_data(patch_path, feature_path, label_path, mapping_infor_path)\n",
    "        \n",
    "    x_Feature = np.expand_dims(input_Feature,axis=0)\n",
    "    x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "    x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "\n",
    "    x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "    x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "    x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "\n",
    "    X = [x_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "    Y = np.expand_dims(label_out, axis=0)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_name = 'ZerNet_faust_correspondence'\n",
    "weights_dir = './Trained Models/faust_train_checkpoints'\n",
    "model.load_weights(os.path.join(weights_dir,trained_model_name))\n",
    "save_folder = './Data/Faust Corrspondence Dataset/ZerNet Predict'\n",
    "\n",
    "for model_name in test_model_names:\n",
    "    \n",
    "    test_X, test_Y = load_test_data(patches_folder, features_folder, labels_folder, mapping_infor_path, model_name)\n",
    "    Yp = model.predict(test_X, batch_size=1)\n",
    "    Yp = np.argmax(Yp, axis=2)\n",
    "    Yp = np.squeeze(Yp)\n",
    "    sio.savemat(os.path.join(save_folder, model_name), {'predict_label':Yp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
