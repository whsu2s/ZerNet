{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, concatenate, Dropout, Reshape, Conv1D, MaxPooling1D, Flatten, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import sys\n",
    "from ZernikeCNN import ZernikeConv, resampleGraph_expand, Normalized_resampleGraph_expand, ZernikeDecomp\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], sio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_patchfeature_input(path):\n",
    "    ZerNet_preproc = loadmat(path)\n",
    "    Input_Patch_Features = ZerNet_preproc['ZerNet_preproc']['scale_1']['ZerPatch']['FeaVec'].astype('float32')\n",
    "    return Input_Patch_Features\n",
    "\n",
    "def load_mapping_infor(path):\n",
    "    sampled_infor = loadmat(path)\n",
    "    mesh_faces = (sampled_infor['sampled_surface']['F']-1).astype('int32')\n",
    "    resample_graph_I = (sampled_infor['sampled_surface']['I']-1).astype('int32')\n",
    "    resample_graph_B = sampled_infor['sampled_surface']['B'].astype('float32')\n",
    "    return mesh_faces, resample_graph_I, resample_graph_B\n",
    "\n",
    "def load_output_stress(path):\n",
    "    sampled_infor = loadmat(path)\n",
    "    stress_out = (sampled_infor['sampled_surface']['J2m']*1000).astype('float32')\n",
    "    return stress_out\n",
    "\n",
    "def load_Zerpatch_input(path, scalename):\n",
    "    ZerNet_preproc = loadmat(path)\n",
    "    Zerbases = ZerNet_preproc['ZerNet_preproc'][scalename]['ZerPatch']['bases'].astype('float32')\n",
    "    resampleGraph = (ZerNet_preproc['ZerNet_preproc'][scalename]['ZerPatch']['resamplePids']-1).astype('int32')\n",
    "    scale ={'Zerbases':Zerbases,\n",
    "            'resampleGraph':resampleGraph}\n",
    "    return scale\n",
    "\n",
    "def create_data(patch_path, sampled_path, argument=False):\n",
    "    scale_1 = load_Zerpatch_input(patch_path, 'scale_1')\n",
    "    Zerbases = scale_1['Zerbases']\n",
    "    resampleGraph = scale_1['resampleGraph']\n",
    "    Disk_Feature = load_patchfeature_input(patch_path)  \n",
    "    stress_out = load_output_stress(sampled_path)\n",
    "    return Disk_Feature,resampleGraph,Zerbases,stress_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_model_names, patches_folder, sampled_folder, argument=False, batch_size=1, cut_num=65, basis_num = 21, \n",
    "                 num_input_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.list_model_names = list_model_names\n",
    "        self.patches_folder = patches_folder\n",
    "        self.sampled_folder = sampled_folder\n",
    "        self.argument = argument\n",
    "        self.cut_num = cut_num\n",
    "        self.basis_num = basis_num\n",
    "        self.batch_size = batch_size\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_model_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index:index+1]\n",
    "\n",
    "        # Find list of model_names\n",
    "        list_model_names_temp = [self.list_model_names[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_model_names_temp)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_model_names))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)        \n",
    "\n",
    "    def __data_generation(self, list_model_names_temp):\n",
    "        'Generates data containing batch_size samples'        \n",
    "        model_name = list_model_names_temp[0]\n",
    "\n",
    "        # Generate data\n",
    "        patch_path = os.path.join(self.patches_folder,model_name)\n",
    "        sampled_path = os.path.join(self.sampled_folder,model_name)\n",
    "            \n",
    "        Disk_Feature,resampleGraph,Zerbases,stress_out = create_data(patch_path,sampled_path,self.argument)\n",
    "        mesh_faces, resample_graph_I, resample_graph_B = load_mapping_infor(sampled_path)\n",
    "        \n",
    "        x_Disk_Feature = np.expand_dims(Disk_Feature,axis=0)\n",
    "        x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "        x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "        \n",
    "        x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "        x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "        x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "        \n",
    "        X = [x_Disk_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "        Y = np.expand_dims(stress_out, axis=-1)\n",
    "        Y = np.expand_dims(Y, axis=0)\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Initial_ZerConv_block(nf, nrays_expand, x_Disk_Feature, x_Zb, dropout_ratio=0.25):\n",
    "    Zercoeff = ZernikeDecomp(angular_axis=False)([x_Disk_Feature,x_Zb])\n",
    "    Features = ZernikeConv(filters = nf, numofrays = nrays_expand, angular_axis = False, \n",
    "                           angular_expand=True,angular_pooling=False, activation='relu')(Zercoeff)\n",
    "    Features = Dropout(dropout_ratio)(Features)\n",
    "    return Features\n",
    "\n",
    "def ZerConv_block(nf,nrays_in,x_Feature, x_rG, x_F, x_I, x_B, x_Zb, pooling=False, dropout_ratio=0.25):\n",
    "    Disk_Features = resampleGraph_expand(angular_axis=True)([x_Feature, x_rG, x_F, x_I, x_B])\n",
    "    Zercoeff = ZernikeDecomp(angular_axis=True, numofrays=nrays_in)([Disk_Features,x_Zb])\n",
    "    Features = ZernikeConv(filters = nf, numofrays = nrays_in, angular_axis = True, \n",
    "                           angular_expand=False,angular_pooling=pooling, activation='relu')(Zercoeff)  \n",
    "    Features = Dropout(dropout_ratio)(Features)\n",
    "    return Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ZerNet(nrays, numofresampledpoints, cut_num, basis_num = 21, num_input_channels=3):\n",
    "    \n",
    "    Disk_Features_in = Input(shape=(None,cut_num,num_input_channels,), dtype = 'float32')\n",
    "    resampleGraph = Input(shape=(None,cut_num,), dtype = 'int32', name = 'rG')\n",
    "    F = Input(shape=(None,3), dtype = 'int32', name = 'F')\n",
    "    I = Input(shape=(numofresampledpoints,), dtype = 'int32', name = 'I')\n",
    "    B = Input(shape=(numofresampledpoints,3,), dtype = 'float32', name = 'B')\n",
    "    Zerbases = Input(shape=(None,cut_num,basis_num,), dtype = 'float32', name = 'Zb')\n",
    "\n",
    "    Features = Initial_ZerConv_block(128,nrays,Disk_Features_in, Zerbases)\n",
    "    Features = ZerConv_block(256, nrays, Features, resampleGraph, F, I, B, Zerbases, pooling=False)\n",
    "    Features = ZerConv_block(512, nrays, Features, resampleGraph, F, I, B, Zerbases, pooling=True)\n",
    "\n",
    "    Features = Conv1D(filters = 800, kernel_size=1, activation='relu')(Features)\n",
    "    Features = Dropout(0.25)(Features)\n",
    "\n",
    "    Features = Conv1D(filters = 1, kernel_size=1, activation='linear')(Features)\n",
    "\n",
    "    model = Model(inputs = [Disk_Features_in,resampleGraph, F, I, B, Zerbases], outputs = Features)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae_percentage_acc(y_true, y_pred):\n",
    "    acc = 100 - mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "patches_folder = './Data/Aneurysm Dataset/ZerNet Input/Input ZerPatches' \n",
    "sampled_folder = './Data/Aneurysm Dataset/UniformSampling_surfaces'\n",
    "\n",
    "model_names = os.listdir(patches_folder)\n",
    "\n",
    "# print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'cut_num': 65,\n",
    "          'basis_num': 21,\n",
    "          'num_input_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "test_model_names = ['TP_Ia166I.mat']\n",
    "train_model_names = list(set(model_names)-set(test_model_names))\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_model_names, patches_folder, sampled_folder, argument=False, **params)\n",
    "validation_generator = DataGenerator(test_model_names, patches_folder, sampled_folder, argument=False, **params)\n",
    "train_steps = len(train_model_names)\n",
    "val_steps = len(test_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, 65, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Zb (InputLayer)                  (None, None, 65, 21)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_1 (ZernikeDecomp) (None, None, 21, 3)   0           input_1[0][0]                    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_1 (ZernikeConv)     (None, None, 1, 128)  8192        zernike_decomp_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, None, 1, 128)  0           zernike_conv_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "rG (InputLayer)                  (None, None, 65)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "F (InputLayer)                   (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "I (InputLayer)                   (None, 8000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "B (InputLayer)                   (None, 8000, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "resample_graph_expand_1 (resampl (None, None, 1, 65, 1 0           dropout_1[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_2 (ZernikeDecomp) (None, None, 1, 21, 1 0           resample_graph_expand_1[0][0]    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_2 (ZernikeConv)     (None, None, 1, 256)  688384      zernike_decomp_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, None, 1, 256)  0           zernike_conv_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "resample_graph_expand_2 (resampl (None, None, 1, 65, 2 0           dropout_2[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_3 (ZernikeDecomp) (None, None, 1, 21, 2 0           resample_graph_expand_2[0][0]    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_3 (ZernikeConv)     (None, None, 512)     2753024     zernike_decomp_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, None, 512)     0           zernike_conv_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, None, 800)     410400      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, None, 800)     0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, None, 1)       801         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3,860,801\n",
      "Trainable params: 3,860,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_input_channels = 3\n",
    "cut_num = 65\n",
    "basis_num = 21\n",
    "numofresampledpoints = 8000\n",
    "nrays = 1 # nrays = 4\n",
    "\n",
    "model = ZerNet(nrays, numofresampledpoints, cut_num, basis_num, num_input_channels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_name = 'ZerNet_aneury_'+ test_model_names[0]\n",
    "weights_dir = './Train Models/aneurysm_train_checkpoints'\n",
    "\n",
    "# model.compile(loss= 'mean_absolute_error', optimizer = adam, metrics=['mse',mae_percentage_acc])\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss= 'mean_absolute_error', optimizer = adam, metrics=['mse',mae_percentage_acc])\n",
    "checkpointer = ModelCheckpoint(filepath= os.path.join(weights_dir, trained_model_name), \n",
    "                               monitor = 'val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "earlystopping = EarlyStopping(monitor='val_mean_squared_error', min_delta=0, patience=30, verbose=0, mode='min')\n",
    "\n",
    "\n",
    "network_history = model.fit_generator(generator=training_generator, steps_per_epoch=train_steps,\n",
    "                                      epochs=200, verbose=1,\n",
    "                                      callbacks=[checkpointer, earlystopping],\n",
    "                                      validation_data=validation_generator,\n",
    "                                      validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(patch_folder, sampled_folder, model_name):\n",
    "    patch_path = os.path.join(patch_folder, model_name)\n",
    "    sampled_path = os.path.join(sampled_folder, model_name)\n",
    "\n",
    "    Disk_Feature,resampleGraph,Zerbases,stress_out = create_data(patch_path,sampled_path)\n",
    "    mesh_faces, resample_graph_I, resample_graph_B = load_mapping_infor(sampled_path)\n",
    "    \n",
    "    x_Disk_Feature = np.expand_dims(Disk_Feature,axis=0)\n",
    "    x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "    x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "        \n",
    "    x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "    x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "    x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "        \n",
    "    X = [x_Disk_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "    Y = np.expand_dims(stress_out, axis=-1)\n",
    "    Y = np.expand_dims(Y, axis=0)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae_acc(yp,y_true):\n",
    "    return (1-np.sum(np.abs(yp - y_true)/y_true)/len(y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "weights_dir = './Train Models/aneurysm_train_checkpoints'\n",
    "predict_folder = './Data/Aneurysm Dataset/ZerNet Predict'\n",
    "\n",
    "model_name = 'TP_Ia166I.mat'\n",
    "model = ZerNet(nrays, numofresampledpoints, cut_num, basis_num, num_input_channels)\n",
    "trained_model_name = 'ZerNet_aneury_'+ model_name\n",
    "\n",
    "model.load_weights(os.path.join(weights_dir, trained_model_name))\n",
    "\n",
    "test_X, test_Y = load_test_data(patches_folder, sampled_folder, model_name)\n",
    "Yp = model.predict(test_X, batch_size=1).flatten()\n",
    "Y = test_Y.flatten()\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(Y, Yp)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(0,220)\n",
    "plt.ylim(0,220)\n",
    "\n",
    "plt.scatter(Y, Yp)\n",
    "print(r_value)\n",
    "\n",
    "Acc = mae_acc(Yp,Y)\n",
    "print(Acc)\n",
    "\n",
    "sio.savemat(os.path.join(predict_folder, model_name),{'predict_J2m':Yp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
