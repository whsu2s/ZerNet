{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, concatenate, Dropout, Reshape, Conv1D, MaxPooling1D, Flatten, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import sys\n",
    "from ZernikeCNN import ZernikeConv, resampleGraph_expand, Normalized_resampleGraph_expand, ZernikeDecomp\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def random_rotation(x_Feature):\n",
    "    x_Feature = x_Feature.transpose()\n",
    "    \n",
    "    axis_y = [0, 1, 0]\n",
    "    theta_list = [-np.pi+np.pi/16*k for k in range(32)]\n",
    "    theta_y = theta_list[np.random.randint(len(theta_list))]\n",
    "    Rot = rotation_matrix(axis_y, theta_y)\n",
    "    \n",
    "    x_Feature = np.matmul(Rot,x_Feature)\n",
    "    x_Feature = x_Feature.transpose()\n",
    "    \n",
    "    return x_Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], sio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_input_feature(path):\n",
    "    sampled_infor = loadmat(path)\n",
    "    input_feature = sampled_infor['sampled_surface']['X'].astype('float32')\n",
    "    return input_feature\n",
    "\n",
    "def load_patchfeature_input(path):\n",
    "    ZerNet_preproc = loadmat(path)\n",
    "    Input_Patch_Features = ZerNet_preproc['ZerNet_preproc']['scale_1']['ZerPatch']['FeaVec'].astype('float32')\n",
    "    return Input_Patch_Features\n",
    "\n",
    "def load_mapping_infor(path):\n",
    "    sampled_infor = loadmat(path)\n",
    "    mesh_faces = (sampled_infor['sampled_surface']['F']-1).astype('int32')\n",
    "    resample_graph_I = (sampled_infor['sampled_surface']['I']-1).astype('int32')\n",
    "    resample_graph_B = sampled_infor['sampled_surface']['B'].astype('float32')\n",
    "    return mesh_faces, resample_graph_I, resample_graph_B\n",
    "\n",
    "def load_output_label(path):\n",
    "    sampled_infor = loadmat(path)\n",
    "    label_out = (sampled_infor['sampled_surface']['label_X']-1).astype('int32')\n",
    "    return label_out\n",
    "\n",
    "def load_Zerpatch_input(path, scalename):\n",
    "    ZerNet_preproc = loadmat(path)\n",
    "    Zerbases = ZerNet_preproc['ZerNet_preproc'][scalename]['ZerPatch']['bases'].astype('float32')\n",
    "    resampleGraph = (ZerNet_preproc['ZerNet_preproc'][scalename]['ZerPatch']['resamplePids']-1).astype('int32')\n",
    "    scale ={'Zerbases':Zerbases,\n",
    "            'resampleGraph':resampleGraph}\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(patch_path, sampled_path, argument=False):\n",
    "    scale_1 = load_Zerpatch_input(patch_path, 'scale_1')\n",
    "    Zerbases = scale_1['Zerbases']\n",
    "    resampleGraph = scale_1['resampleGraph']\n",
    "    Disk_Feature = load_patchfeature_input(patch_path)  \n",
    "    label_out = load_output_label(sampled_path)\n",
    "    return Disk_Feature,resampleGraph,Zerbases,label_out\n",
    "\n",
    "# def create_data(patch_path, sampled_path, argument):\n",
    "#     scale_1 = load_Zerpatch_input(patch_path, 'scale_1')\n",
    "#     Zerbases = scale_1['Zerbases']\n",
    "#     resampleGraph = scale_1['resampleGraph']\n",
    "#     input_feature = load_input_feature(sampled_path)\n",
    "#     if argument:\n",
    "#         #random scaleing and rotation\n",
    "# #         scaling_factor = (1.15-0.85)*random.uniform(0, 1)+0.85\n",
    "# #         input_feature = scaling_factor*input_feature\n",
    "#           input_feature = random_rotation(input_feature)  \n",
    "#     label_out = load_output_label(sampled_path)\n",
    "#     return input_feature,resampleGraph,Zerbases,label_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_model_names, patches_folder, sampled_folder, argument=False, batch_size=1, basis_num = 21, \n",
    "                 num_input_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.list_model_names = list_model_names\n",
    "        self.patches_folder = patches_folder\n",
    "        self.sampled_folder = sampled_folder\n",
    "        self.argument = argument\n",
    "        self.basis_num = basis_num\n",
    "        self.batch_size = batch_size\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_model_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        indexes = self.indexes[index:index+1]\n",
    "\n",
    "        # Find list of model_names\n",
    "        list_model_names_temp = [self.list_model_names[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_model_names_temp)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_model_names))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)        \n",
    "\n",
    "    def __data_generation(self, list_model_names_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        model_name = list_model_names_temp[0]\n",
    "\n",
    "        # Generate data\n",
    "        patch_path = os.path.join(self.patches_folder,model_name)\n",
    "        sampled_path = os.path.join(self.sampled_folder,model_name)\n",
    "            \n",
    "        Disk_Feature,resampleGraph,Zerbases,label_out = create_data(patch_path,sampled_path,self.argument)\n",
    "        mesh_faces, resample_graph_I, resample_graph_B = load_mapping_infor(sampled_path)\n",
    "        \n",
    "        x_Disk_Feature = np.expand_dims(Disk_Feature,axis=0)\n",
    "        x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "        x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "        \n",
    "        x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "        x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "        x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "        \n",
    "        X = [x_Disk_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "        Y = np.expand_dims(label_out, axis=-1)\n",
    "        Y = np.expand_dims(Y, axis=0)\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "patches_folder = './Data/Faust Segmentation Dataset/ZerNet Input/Input ZerPatches' \n",
    "sampled_folder = './Data/Faust Segmentation Dataset/UniformSampling_surfaces'\n",
    "\n",
    "# model_names = os.listdir(patches_folder)\n",
    "# print(model_names)\n",
    "\n",
    "model_names = []\n",
    "for i in range(100):\n",
    "    model_id = 1000+i;\n",
    "    model_id = str(model_id)[1:]\n",
    "    model_name = 'faust_tr_reg_' + model_id + '.mat'\n",
    "    model_names.append(model_name)\n",
    "# print(model_names)\n",
    "\n",
    "val_start_id = 80\n",
    "val_range = np.array(range(val_start_id,val_start_id+20))\n",
    "\n",
    "total_range = np.array(range(len(model_names)))\n",
    "train_range = np.setdiff1d(total_range,val_range)\n",
    "\n",
    "train_model_names = model_names[train_range[0]:train_range[-1]+1]\n",
    "val_model_names = model_names[val_range[0]:val_range[-1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'basis_num': 21,\n",
    "          'num_input_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_model_names, patches_folder, sampled_folder, argument=False, **params)\n",
    "validation_generator = DataGenerator(val_model_names, patches_folder, sampled_folder, argument=False, **params)\n",
    "\n",
    "train_steps = len(train_model_names)\n",
    "val_steps = len(val_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Initial_ZerConv_block(nf, nrays_expand, x_Disk_Feature, x_Zb, dropout_ratio=0.25):\n",
    "    Zercoeff = ZernikeDecomp(angular_axis=False)([x_Disk_Feature,x_Zb])\n",
    "    Features = ZernikeConv(filters = nf, numofrays = nrays_expand, angular_axis = False, \n",
    "                           angular_expand=True,angular_pooling=False, activation='relu')(Zercoeff)\n",
    "    Features = Dropout(dropout_ratio)(Features)\n",
    "    return Features\n",
    "\n",
    "\n",
    "def ZerConv_block(nf,nrays_in,x_Feature, x_rG, x_F, x_I, x_B, x_Zb, pooling=False, dropout_ratio=0.25):\n",
    "    Disk_Features = resampleGraph_expand(angular_axis=True)([x_Feature, x_rG, x_F, x_I, x_B])\n",
    "    Zercoeff = ZernikeDecomp(angular_axis=True, numofrays=nrays_in)([Disk_Features,x_Zb])\n",
    "    Features = ZernikeConv(filters = nf, numofrays = nrays_in, angular_axis = True, \n",
    "                           angular_expand=False,angular_pooling=pooling, activation='relu')(Zercoeff)  \n",
    "    Features = Dropout(dropout_ratio)(Features)\n",
    "    return Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, 50, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Zb (InputLayer)                  (None, None, 50, 21)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_1 (ZernikeDecomp) (None, None, 21, 3)   0           input_1[0][0]                    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_1 (ZernikeConv)     (None, None, 1, 32)   2048        zernike_decomp_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, None, 1, 32)   0           zernike_conv_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "rG (InputLayer)                  (None, None, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "F (InputLayer)                   (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "I (InputLayer)                   (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "B (InputLayer)                   (None, None, 3)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "resample_graph_expand_1 (resampl (None, None, 1, 50, 3 0           dropout_1[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_2 (ZernikeDecomp) (None, None, 1, 21, 3 0           resample_graph_expand_1[0][0]    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_2 (ZernikeConv)     (None, None, 1, 64)   43072       zernike_decomp_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, None, 1, 64)   0           zernike_conv_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "resample_graph_expand_2 (resampl (None, None, 1, 50, 6 0           dropout_2[0][0]                  \n",
      "                                                                   rG[0][0]                         \n",
      "                                                                   F[0][0]                          \n",
      "                                                                   I[0][0]                          \n",
      "                                                                   B[0][0]                          \n",
      "____________________________________________________________________________________________________\n",
      "zernike_decomp_3 (ZernikeDecomp) (None, None, 1, 21, 6 0           resample_graph_expand_2[0][0]    \n",
      "                                                                   Zb[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zernike_conv_3 (ZernikeConv)     (None, None, 128)     172160      zernike_decomp_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, None, 128)     0           zernike_conv_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, None, 256)     33024       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, None, 256)     0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, None, 8)       2056        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 252,360\n",
      "Trainable params: 252,360\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_input_channels = 3\n",
    "cut_num = 50\n",
    "basis_num = 21\n",
    "n_classes = 8\n",
    "nrays = 1\n",
    "\n",
    "Disk_Features_in = Input(shape=(None,cut_num,num_input_channels,), dtype = 'float32')\n",
    "resampleGraph = Input(shape=(None,cut_num,), dtype = 'int32', name = 'rG')\n",
    "F = Input(shape=(None,3), dtype = 'int32', name = 'F')\n",
    "I = Input(shape=(None,), dtype = 'int32', name = 'I')\n",
    "B = Input(shape=(None,3,), dtype = 'float32', name = 'B')\n",
    "Zerbases = Input(shape=(None,cut_num,basis_num,), dtype = 'float32', name = 'Zb')\n",
    "\n",
    "Features = Initial_ZerConv_block(32,nrays,Disk_Features_in, Zerbases)\n",
    "Features = ZerConv_block(64, nrays, Features, resampleGraph, F, I, B, Zerbases, pooling=False)\n",
    "Features = ZerConv_block(128, nrays, Features, resampleGraph, F, I, B, Zerbases, pooling=True)\n",
    "\n",
    "Features = Conv1D(filters = 256, kernel_size=1, activation='relu')(Features)\n",
    "Features = Dropout(0.25)(Features)\n",
    "Features = Conv1D(filters = n_classes, kernel_size=1, activation='softmax')(Features)\n",
    "model = Model(inputs = [Disk_Features_in,resampleGraph, F, I, B, Zerbases], outputs = Features)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss= 'sparse_categorical_crossentropy', optimizer = adam, metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "weights_dir = './Trained Models/seg_train_checkpoints'\n",
    "\n",
    "trained_model_name = 'ZerNet_faust_segmentation'\n",
    "checkpointer = ModelCheckpoint(filepath = os.path.join(weights_dir, trained_model_name),\n",
    "                               monitor = 'val_sparse_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_sparse_categorical_accuracy', min_delta=0.001, patience=35, verbose=0, mode='max')\n",
    "\n",
    "network_history = model.fit_generator(generator=training_generator, steps_per_epoch=train_steps,\n",
    "                                      epochs=200, verbose=1,\n",
    "                                      callbacks=[checkpointer, earlystopping],\n",
    "                                      validation_data=validation_generator,\n",
    "                                      validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(patches_folder, sampled_folder, model_name):\n",
    "    patch_path = os.path.join(patches_folder,model_name)\n",
    "    sampled_path = os.path.join(sampled_folder,model_name)\n",
    "            \n",
    "    input_Feature,resampleGraph,Zerbases,label_out = create_data(patch_path,sampled_path,False)\n",
    "    mesh_faces, resample_graph_I, resample_graph_B = load_mapping_infor(sampled_path)\n",
    "        \n",
    "    x_Feature = np.expand_dims(input_Feature,axis=0)\n",
    "    x_rG = np.expand_dims(resampleGraph,axis=0)\n",
    "    x_Zb = np.expand_dims(Zerbases,axis=0)\n",
    "        \n",
    "    x_F = np.expand_dims(mesh_faces,axis=0)\n",
    "    x_I = np.expand_dims(resample_graph_I,axis=0)\n",
    "    x_B = np.expand_dims(resample_graph_B,axis=0)\n",
    "        \n",
    "    X = [x_Feature, x_rG, x_F, x_I, x_B, x_Zb]\n",
    "    Y = np.expand_dims(label_out, axis=-1)\n",
    "    Y = np.expand_dims(Y, axis=0)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_folder = './Data/Faust Segmentation Dataset/ZerNet Predict'\n",
    "model.load_weights(os.path.join(weights_dir,trained_model_name))\n",
    "\n",
    "for model_name in val_model_names:\n",
    "    \n",
    "    test_X, test_Y = load_test_data(patches_folder, sampled_folder, model_name)\n",
    "    Yp = model.predict(test_X, batch_size=1)\n",
    "    Yp = np.argmax(Yp, axis=2)\n",
    "    Yp = np.squeeze(Yp)\n",
    "    \n",
    "    sio.savemat(os.path.join(predict_folder, model_name), {'predict_label':Yp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
